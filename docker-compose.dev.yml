services:
  celery_beat:
    build:
      context: .
      dockerfile: Dockerfile.dev
    container_name: celery_beat
    command: celery -A scraper.tasks beat --loglevel=info
    environment:
      - PYTHONPATH=/scraper:/
      - PYTHONUNBUFFERED=1
      - LOG_LEVEL=INFO
    depends_on:
      - redis
    volumes:
      - .:/scraper
    networks:
      - my_probe_network

  redis:
    image: redis:alpine
    container_name: redis
    volumes:
      - redis_data:/data
    ports:
      - "6379:6379"
    networks:
      - my_probe_network

  celery_worker_1:
    build:
      context: .
      dockerfile: Dockerfile.dev
    container_name: celery_worker_1
    platform: linux/arm64
    command: celery -A scraper.tasks worker --loglevel=info
    environment:
      - PYTHONPATH=/scraper:/
      - PYTHONUNBUFFERED=1
      - LOG_LEVEL=DEBUG
    depends_on:
      - redis
      - elasticsearch
    volumes:
      - .:/scraper
    networks:
      - my_probe_network

  celery_worker_2:
    build:
      context: .
      dockerfile: Dockerfile.dev
    container_name: celery_worker_2
    platform: linux/arm64
    command: celery -A scraper.tasks worker --loglevel=info
    environment:
      - PYTHONPATH=/scraper:/
      - PYTHONUNBUFFERED=1
      - LOG_LEVEL=DEBUG
    depends_on:
      - redis
      - elasticsearch
    volumes:
      - .:/scraper
    networks:
      - my_probe_network

  elasticsearch:
    container_name: elasticsearch
    image: docker.elastic.co/elasticsearch/elasticsearch:8.15.0
    environment:
      - discovery.type=single-node
      - ES_JAVA_OPTS=-Xms512m -Xmx512m
      - "ELASTIC_PASSWORD=changeme" # Set your password here
    volumes:
      - es_data:/usr/share/elasticsearch/data
    ports:
      - "9200:9200"
    networks:
      - my_probe_network
    restart: always

volumes:
  es_data:
  logs_volume:
  redis_data:

networks:
  my_probe_network:
    external: true

# docker-compose.dev.yml